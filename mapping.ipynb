{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple tutorial to map a model to the AKIDA1000 hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from quantizeml.models import quantize\n",
    "from cnn2snn import convert\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cnn2snn\n",
    "import akida as ak\n",
    "from quantizeml.models import quantize\n",
    "from quantizeml.layers import QuantizationParams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the akida env version to v1 is very important to port it to hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "    TF version:  2.15.0\n",
      "MetaTF version:  2.11.0\n",
      " Akida version:  AkidaVersion.v1\n",
      "----------------------------------\n",
      "/home/kannan/anaconda3/envs/tf_env/bin/python\n",
      "Time of run:  2025-11-10_17-30\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CNN2SNN_TARGET_AKIDA_VERSION\"] = \"v1\"\n",
    "print('----------------------------------')\n",
    "print(\"    TF version: \", tf.__version__)\n",
    "print(\"MetaTF version: \", ak.__version__)\n",
    "print(' Akida version: ', cnn2snn.get_akida_version()) \n",
    "print('----------------------------------')\n",
    "\n",
    "!which python\n",
    "\n",
    "today = datetime.datetime.now()\n",
    "todayAsStr = str(today.year) + '-' + str(today.month) + '-' + str(today.day) + '_' + str(today.hour) + '-' + str(today.minute)\n",
    "print('Time of run: ', todayAsStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Base model + weights loaded successfully!\n",
      "Model: \"akida_friendly_cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 60, 76, 16)        416       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 30, 38, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 30, 38, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 15, 19, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 15, 19, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 8, 10, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 8, 10, 64)         4160      \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 5120)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                327744    \n",
      "                                                                 \n",
      " dense_out (Dense)           (None, 2280)              148200    \n",
      "                                                                 \n",
      " reshape_out (Reshape)       (None, 30, 76)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 503656 (1.92 MB)\n",
      "Trainable params: 503656 (1.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "ðŸ§© New model without final Reshape:\n",
      "Model: \"akida_friendly_cnn_flat\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 60, 76, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 60, 76, 16)        416       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 30, 38, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 30, 38, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 15, 19, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 15, 19, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 8, 10, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 8, 10, 64)         4160      \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 5120)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                327744    \n",
      "                                                                 \n",
      " dense_out (Dense)           (None, 2280)              148200    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 503656 (1.92 MB)\n",
      "Trainable params: 503656 (1.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Flat output shape: (1, 2280)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Rebuild ESA ConvNet and load weights (TF 2.15 compatible),\n",
    "then cut off the final Reshape to get a flat (2280,) output.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# --- Architecture (same as your training script) ---\n",
    "def build_sequential_model(window, n_channels, forecast_horizon=None):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(window, n_channels, 1)),\n",
    "        tf.keras.layers.Conv2D(16, (5,5), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64, (1,1), padding='same', activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "\n",
    "        tf.keras.layers.Dense(forecast_horizon * n_channels, activation='linear', name=\"dense_out\"),\n",
    "        tf.keras.layers.Reshape((forecast_horizon, n_channels), name=\"reshape_out\"),\n",
    "    ], name=\"akida_friendly_cnn\")\n",
    "    return model\n",
    "\n",
    "# --- Params (match training) ---\n",
    "WINDOW = 60\n",
    "N_CHANNELS = 76\n",
    "FORECAST = 30\n",
    "WEIGHTS_PATH = \"ESA_cnn_simon.weights.h5\"   # your weights file path\n",
    "\n",
    "# --- Build + load ---\n",
    "base_model = build_sequential_model(WINDOW, N_CHANNELS, FORECAST)\n",
    "base_model.load_weights(WEIGHTS_PATH)\n",
    "print(\"\\nâœ… Base model + weights loaded successfully!\")\n",
    "base_model.summary()\n",
    "\n",
    "# --- Cut off the final Reshape layer, keep flat Dense(2280) output ---\n",
    "# Last two layers are: Dense(..., name=\"dense_out\") then Reshape(..., name=\"reshape_out\")\n",
    "flat_output = base_model.get_layer(\"dense_out\").output  # shape: (None, 2280)\n",
    "flat_model = Model(inputs=base_model.input, outputs=flat_output, name=\"akida_friendly_cnn_flat\")\n",
    "\n",
    "print(\"\\nðŸ§© New model without final Reshape:\")\n",
    "flat_model.summary()\n",
    "\n",
    "# Optional: compile (use any metrics you need)\n",
    "flat_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.MeanAbsoluteError(),\n",
    "             tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "# Quick forward test\n",
    "x_dummy = np.zeros((1, WINDOW, N_CHANNELS, 1), dtype=np.float32)\n",
    "y_pred_flat = flat_model(x_dummy)\n",
    "print(\"Flat output shape:\", y_pred_flat.shape)  # expect (1, 30*76) = (1, 2280)\n",
    "\n",
    "# (Optional) Save this trimmed model for quantization/compat checks\n",
    "# flat_model.save(\"ESA_cnn_simon_flat_savedmodel\")  # SavedModel folder\n",
    "# flat_model.save_weights(\"ESA_cnn_simon_flat.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Load trained model \n",
    "# model_src = tf.keras.models.load_model(\"ESA_cnn_simon.h5\", compile=False)\n",
    "# model_src.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Weights loaded into bounded-ReLU flat model.\n",
      "Output shape (should be 2280): (1, 2280)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def build_flat_bounded_model(window, n_channels, forecast_horizon):\n",
    "\n",
    "    ReLU6 = lambda name=None: tf.keras.layers.ReLU(max_value=6.0, name=name)\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(window, n_channels, 1), name=\"input\"),\n",
    "        tf.keras.layers.Conv2D(16, (5,5), padding='same', name=\"conv1\"),\n",
    "        ReLU6(\"relu1\"),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same', name=\"pool1\"),\n",
    "\n",
    "        tf.keras.layers.Conv2D(32, (3,3), padding='same', name=\"conv2\"),\n",
    "        ReLU6(\"relu2\"),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same', name=\"pool2\"),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64, (3,3), padding='same', name=\"conv3\"),\n",
    "        ReLU6(\"relu3\"),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same', name=\"pool3\"),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64, (1,1), padding='same', name=\"conv4\"),\n",
    "        ReLU6(\"relu4\"),\n",
    "\n",
    "        tf.keras.layers.Flatten(name=\"flatten\"),\n",
    "        tf.keras.layers.Dense(64, name=\"fc1\"),\n",
    "        ReLU6(\"relu_fc1\"),\n",
    "\n",
    "        # Flat output (no reshape) â€” safer for quantizers\n",
    "        tf.keras.layers.Dense(forecast_horizon * n_channels, activation='linear', name=\"dense_out\"),\n",
    "    ], name=\"akida_friendly_cnn_flat_relu6\")\n",
    "\n",
    "# --- Params (match training) ---\n",
    "WINDOW    = 60\n",
    "N_CHANNEL = 76\n",
    "FORECAST  = 30\n",
    "WEIGHTS   = \"ESA_cnn_simon.weights.h5\"   # your weights file\n",
    "\n",
    "\n",
    "base = build_flat_bounded_model(WINDOW, N_CHANNEL, FORECAST)\n",
    "\n",
    "try:\n",
    "    base.load_weights(WEIGHTS)\n",
    "except Exception as e:\n",
    "    print(\"load_weights issue:\", e)\n",
    "\n",
    "x_dummy = np.zeros((1, WINDOW, N_CHANNEL, 1), dtype=np.float32)\n",
    "y = base(x_dummy)\n",
    "print(\"Output shape (should be 2280):\", y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 302ms/step\n",
      "Compatibility issues:  None\n"
     ]
    }
   ],
   "source": [
    "compatibilityIssues = cnn2snn.check_model_compatibility(base, device=ak.AKD1000())\n",
    "print('Compatibility issues: ', compatibilityIssues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantizeml.models import quantize\n",
    "from quantizeml.layers import QuantizationParams\n",
    "\n",
    "# Quantize the model\n",
    "qparams = QuantizationParams(input_weight_bits=8, weight_bits=4, activation_bits=4, per_tensor_activations=True)\n",
    "model_quantized = quantize(model_src, qparams=qparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Akida version check: ', cnn2snn.get_akida_version()) \n",
    "akida_model = cnn2snn.convert(model_quantized, file_path='akida_model.fbz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akida_model = cnn2snn.convert(model_quantized, file_path='akida_model.fbz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model version: ', akida_model.ip_version, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
